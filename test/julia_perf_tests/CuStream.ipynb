{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CuDevice(5): Tesla V100-SXM2-32GB"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "using NVTX\n",
    "using CUDA\n",
    "\n",
    "device!(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Kernal functions on the GPU:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "function kernelA(a)\n",
    "    i = threadIdx().x\n",
    "    a[i] *= 2\n",
    "    return nothing\n",
    "end\n",
    "\n",
    "function kernelB(b)\n",
    "    i = threadIdx().x\n",
    "    b[i] += 3\n",
    "    return nothing\n",
    "end\n",
    "nothing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Main function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "function test1(N, a, b, stream1, stream2)\n",
    "    @sync begin\n",
    "        @async begin\n",
    "            NVTX.@range \"stream_1_kernel\" @cuda threads=N stream=stream1 kernelA(a)\n",
    "        end\n",
    "        @async begin\n",
    "            NVTX.@range \"stream_2_kernel\" @cuda threads=N stream=stream2 kernelB(b)\n",
    "        end\n",
    "    end\n",
    "    # synchronize the two streams\n",
    "    CUDA.@sync(stream1)\n",
    "    CUDA.@sync(stream2)\n",
    "    # copy the results back to host\n",
    "    a_host = Array(a)\n",
    "    b_host = Array(b)\n",
    "    return a_host, b_host\n",
    "end\n",
    "nothing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Prepare the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize two vectors\n",
    "N = 256\n",
    "a = CUDA.fill(1.0f0, N)\n",
    "b = CUDA.fill(1.0f0, N)\n",
    "\n",
    "# create two streams on GPU\n",
    "stream1 = CuStream()\n",
    "stream2 = CuStream()\n",
    "nothing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Run with Nsight System"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Float32[2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0  …  2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0], Float32[4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0  …  4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "CUDA.@profile external=true a_host, b_host = test1(N, a, b, stream1, stream2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![image.png](./assets/p01.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Serial version:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "function test2(N, a, b)\n",
    "    NVTX.@range \"kernel_1\" @cuda threads=N kernelA(a)\n",
    "    NVTX.@range \"kernel_2\" @cuda threads=N kernelB(b)\n",
    "    # copy the results back to host\n",
    "    a_host = Array(a)\n",
    "    b_host = Array(b)\n",
    "    return a_host, b_host\n",
    "end\n",
    "CUDA.@profile external=true a_host, b_host = test2(N, a, b)\n",
    "nothing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![image.png](./assets/p02.png)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.9.3",
   "language": "julia",
   "name": "julia-1.9"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.9.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
